{% tabs %}{% tab title='HR_nlp-compute-the-cross-entropy.md' %}

* Given perplexity of a bigram model, compute its cross-entropy corrected to 2 decimal places

```txt
Input: 170
Output: 7.41
```

{% endtab %}{% tab title='HR_nlp-compute-the-cross-entropy.py' %}

```py
import math
print(math.log2(int(input())))
```

{% endtab %}{% endtabs %}
