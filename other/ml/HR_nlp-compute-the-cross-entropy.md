# [HR_nlp-compute-the-cross-entropy](https://www.hackerrank.com/challenges/nlp-compute-the-cross-entropy)

```en
Given perplexity of a bigram model, compute its cross-entropy corrected to 2 decimal places
```

```txt
Input: 170
Output: 7.41
```

## Solution

* py

  ```py
  import math
  print(math.log2(int(input())))
  ```
